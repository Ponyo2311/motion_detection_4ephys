{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26d507dd-6a04-4450-b9df-9dddba73ff05",
   "metadata": {},
   "source": [
    "# GIT \n",
    "\n",
    "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\n",
    "\n",
    "# CHANGES:\n",
    "\n",
    "1) How LONG is the video exactly in ephys time\n",
    "\n",
    "2) devide the screen manually\n",
    "\n",
    "3) normalize mvm\n",
    "\n",
    "4) SAVE mvm-VIDEO mp4 \n",
    "\n",
    "- maybe: downsample to 1 second-resolution\n",
    "\n",
    "5) make it inspectable from plot & zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99fd014-6c8e-4235-bc03-7415c2ca3c15",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67f70638-baf7-4227-bb1e-5c1ede7d4a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime\n",
    "\n",
    "from vpp.motion_detector import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6332b5c-1721-420c-8aea-45348de9fd19",
   "metadata": {},
   "source": [
    "## **HOW LONG IS THE EPHYS TIME - is it the same as video?**\n",
    "\n",
    "- read ephys \n",
    "- diff the file\n",
    "- sum diffs\n",
    "- convert to secs\n",
    "- convert to dateTime object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1d4b7b6-7ec6-4bfe-a99c-f8bd289c0d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getting_ephys_duration(ephys_time_path):\n",
    "    \"\"\"Calculate duration of ephys timestamp file from differences \n",
    "    between points\n",
    "    \n",
    "    goal => compare to exact duration of video\"\"\"\n",
    "    \n",
    "    #read Ephys\n",
    "    e = open(ephys_time_path,\"r\")\n",
    "    ephys_time = [[int(x) for x in line.split()] for line in e]\n",
    "    e.close()\n",
    "    ephys_time = np.concatenate(ephys_time)\n",
    "\n",
    "    #convert eph to millisec \n",
    "    ephys_time = ephys_time/2.5          \n",
    "    \n",
    "    #diffs in millisec\n",
    "    diff_ephys_time = np.diff(ephys_time)\n",
    "    \n",
    "    #total duration in millisec\n",
    "    duration_ms = np.sum(diff_ephys_time)\n",
    "    #print(duration_ms)\n",
    "    \n",
    "    #convert duration to time\n",
    "    total_duration = datetime.timedelta(milliseconds=float(duration_ms))\n",
    "    \n",
    "    #printable -> to string\n",
    "    total_duration=str(total_duration)\n",
    "    \n",
    "    return total_duration[:-3] #last three are microsecs\n",
    "\n",
    "    #if u need ephys starting at 0:\n",
    "    #ephys_time_0 = [i - ephys_time[0] for i in ephys_time]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce2d14-84e4-4a60-8057-d51ef13e4d81",
   "metadata": {},
   "source": [
    "## 1st of July\n",
    "\n",
    "### **1) Video of the same length (timewise) than ephys**\n",
    "\n",
    "=> let's resample to milliseconds.. then pick ephys time precisly?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "99ea9f64-be8b-4dec-a189-ccc1109a94a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path\n",
    "ephys_1st_July=\"/media/data-119/rat596_20210701_184333/rat596_20210701_184333tmstp.txt\"\n",
    "vid_path_1st_July=\"/media/data-119/rat596_20210701_184333/rat596_20210701_184333.mp4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "45937db6-3a2b-47fa-846a-138de0a2d2d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53477480.800000004\n"
     ]
    }
   ],
   "source": [
    "#duration ephys\n",
    "duration_1stJuly=getting_ephys_duration(ephys_1st_July)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "12467048-cff4-40ac-9012-de2f92e10cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'14:51:17.480'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_1stJuly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac18be0-1346-4acf-92ca-ef8b46161524",
   "metadata": {},
   "source": [
    "duration of video: \n",
    "\n",
    "14:51:17 #properties of video file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d9be29-717a-478c-9b2e-d374960e4b1a",
   "metadata": {},
   "source": [
    "### 3) **SAVE MOTION MP4**\n",
    "\n",
    "**Writing a video with openCV**\n",
    "\n",
    "https://learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "For images, it is straightforward. We just need to use cv2.imwrite(). But for videos, we need to toil a bit harder. We need to create a VideoWriter object. First, we should specify the output file name with its format (eg: output.avi). Then, we should specify the FourCC code and the number of frames per second (FPS). Lastly, the frame size should be passed.\n",
    "\n",
    "**Edge detection using Canny**\n",
    "\n",
    "https://docs.opencv.org/3.4/da/d22/tutorial_py_canny.html\n",
    "\n",
    "    Syntax: cv2.Canny(image, T_lower, T_upper, aperture_size, L2Gradient)\n",
    "\n",
    "    Where: \n",
    "\n",
    "        Image: Input image to which Canny filter will be applied\n",
    "        T_lower: Lower threshold value in Hysteresis Thresholding\n",
    "        T_upper: Upper threshold value in Hysteresis Thresholding\n",
    "        aperture_size: Aperture size of the Sobel filter.\n",
    "        L2Gradient: Boolean parameter used for more precision in calculating Edge Gradient.\n",
    "        \n",
    "_wikipedia_\n",
    "The **Sobel operator**, sometimes called the Sobel–Feldman operator or Sobel filter, is used in image processing and computer vision, particularly within edge detection algorithms where it creates an image emphasising edges. It is named after Irwin Sobel and Gary Feldman, colleagues at the Stanford Artificial Intelligence Laboratory (SAIL). Sobel and Feldman presented the idea of an \"Isotropic 3 × 3 Image Gradient Operator\" at a talk at SAIL in 1968.[1] Technically, it is a discrete differentiation operator, computing an approximation of the gradient of the image intensity function. At each point in the image, the result of the Sobel–Feldman operator is either the corresponding gradient vector or the norm of this vector. The Sobel–Feldman operator is based on convolving the image with a small, separable, and integer-valued filter in the horizontal and vertical directions and is therefore relatively inexpensive in terms of computations. On the other hand, the gradient approximation that it produces is relatively crude, in particular for high-frequency variations in the image. \n",
    "\n",
    "https://scikit-image.org/docs/stable/auto_examples/filters/plot_hysteresis.html\n",
    "**Hysteresis Thresholding**\n",
    "Hysteresis is the lagging of an effect—a kind of inertia. In the context of thresholding, it means that areas above some low threshold are considered to be above the threshold if they are also connected to areas above a higher, more stringent, threshold. They can thus be seen as continuations of these high-confidence areas.\n",
    "\n",
    "Below, we compare normal thresholding to hysteresis thresholding. Notice how hysteresis allows one to ignore “noise” outside of the coin edges.\n",
    "\n",
    "https://docs.opencv.org/3.4/da/d5c/tutorial_canny_detector.html\n",
    "Hysteresis: The final step. Canny does use two thresholds (upper and lower):\n",
    "\n",
    "    If a pixel gradient is higher than the upper threshold, the pixel is accepted as an edge\n",
    "    If a pixel gradient value is below the lower threshold, then it is rejected.\n",
    "    If the pixel gradient is between the two thresholds, then it will be accepted only if it is connected to a pixel that is above the upper threshold.\n",
    "\n",
    "Canny recommended a upper:lower ratio between 2:1 and 3:1.\n",
    "\n",
    "**SHOULD DO** (apply mask and not search for coordinates)\n",
    "Applies the Canny Detector and generates a mask (bright lines representing the edges on a black background).\n",
    "Applies the mask obtained on the original image and display it in a window.\n",
    "\n",
    "**HOUGHLINES**\n",
    "https://docs.opencv.org/3.4/d9/db0/tutorial_hough_lines.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e378636-6f98-488f-be41-65936d358c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXAMPLE FROM https://www.programcreek.com/python/example/89361/cv2.Canny\n",
    "def detect_lines(self, canny_low_thresh, canny_high_thresh, canny_kernel_size,\n",
    "                     hough_rho_res, hough_theta_res, hough_votes_thresh,\n",
    "                     gray_conversion=cv2.COLOR_BGR2GRAY):\n",
    "        \"\"\"\n",
    "        Detect lines in input image using hough transform.\n",
    "        Return detected lines as list with tuples:\n",
    "        (rho, theta, normalized theta with 0 <= theta_norm < np.pi, DIRECTION_VERTICAL or DIRECTION_HORIZONTAL)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.gray_img = cv2.cvtColor(self.input_img, gray_conversion)\n",
    "        self.edges = cv2.Canny(self.gray_img, canny_low_thresh, canny_high_thresh, apertureSize=canny_kernel_size)\n",
    "        \n",
    "        # detect lines with hough transform\n",
    "        lines = cv2.HoughLines(self.edges, hough_rho_res, hough_theta_res, hough_votes_thresh)\n",
    "        if lines is None:\n",
    "            lines = []\n",
    "        \n",
    "        self.lines_hough = self._generate_hough_lines(lines)\n",
    "        \n",
    "        return self.lines_hough "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d01fa4fd-ba6f-4222-94f0-b28298af7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#install and set up ipywidgets\n",
    "import ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351dafa-e85c-40e4-ac0e-de38cd119dd8",
   "metadata": {},
   "source": [
    "## for outputting/ writing vids\n",
    "https://stackoverflow.com/questions/30509573/writing-an-mp4-video-using-python-opencv\n",
    "https://www.codegrepper.com/code-examples/python/cv2+save+video+mp4\n",
    "https://www.programcreek.com/python/example/72134/cv2.VideoWriter\n",
    "https://learnopencv.com/read-write-and-display-a-video-using-opencv-cpp-python/\n",
    "https://stackoverflow.com/questions/30509573/writing-an-mp4-video-using-python-opencv\n",
    "https://stackoverflow.com/questions/29317262/opencv-video-saving-in-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465ba565-3e71-4f87-814a-aed252e63ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def motion_detector_outputs(path, scale_percent=40, area=20, delta_thresh=5,\n",
    "                    output_4csv=\"/home/domi/Documents/video_processing/CSV_data\",\n",
    "                   output_rat1_mp4=\"/media/data-119/rat596_20210701_184333/rat596_20210701_184333mvm.mp4\",\n",
    "                   output_rat2_mp4=\"/media/data-119/rat602_20210701_184333/rat602_20210701_184333mvm.mp4\"):\n",
    "    \"\"\"\n",
    "    path: path to the video\n",
    "    area: minimum area size.... TO INCLUDE!!!\n",
    "    output_4csv: it's not txt file yet.. you can precise that later\n",
    "    output mp4s: will write mp4 file saving detected mvm -> inspect it later whether synched\n",
    "    \"\"\"\n",
    "    \n",
    "    #if specified output folder doesn't exist, create it\n",
    "    if not os.path.exists(output_4csv):\n",
    "        os.mkdir(output_4csv)\n",
    "\n",
    "    # read from a video file & get video parameter FramePerSec (FPS)\n",
    "    vs = cv2.VideoCapture(path)\n",
    "    fps_vs = vs.get(cv2.CAP_PROP_FPS)\n",
    "    print(\"Estimated frame rate of the file: {}\".format(fps_vs))\n",
    "    \n",
    "    # initiate dimensions for splitting -> INPUT WITH WIDGETS -> personalized delimitation ----------------------------------\n",
    "    #------------------------------------------------------------------------------------------------------------------------\n",
    "    # n_rows=1\n",
    "    #n_cols = 2  # 2 rats = 2 parts split with a vertical line\n",
    "    # DIVISION IN THE MIDDLE-------------------------------------------------------------------------------------------------\n",
    "    \n",
    "    #division step1: read first frame (you'll have to reuse it in while loop)\n",
    "    ret, frame = vs.read()\n",
    "\n",
    "    #initiate PROCESSING FramePerSec (FPS) count\n",
    "    fps = FPS().start()\n",
    "    \n",
    "    #DEFINE THE CODEC AND CREATE VideoWriter object.The output is stored in '*.MP4' file. (try for both rats simultaneously)--------------------------------\n",
    "    #---------------------------------------------------------------------------------------------------------------------\n",
    "    # try initiate 2 videowriter objects\n",
    "    out_rat1 = cv2.VideoWriter(output_rat1_mp4,cv2.VideoWriter_fourcc('m','p','4','v'), 10, (frame_width,frame_height))\n",
    "    out_rat2 = cv2.VideoWriter(output_rat2_mp4,cv2.VideoWriter_fourcc('m','p','4','v'), 10, (frame_width,frame_height))\n",
    "    \n",
    "    # initialize average frame, frame delta and thresholded frame\n",
    "    avgframe = [[], []]\n",
    "    frameDelta = [[], []]\n",
    "    thresh = [[], []]\n",
    "\n",
    "    # initiate dictionary\n",
    "    ts_dict = {\"frame_nb\": [], \"millisec\": [], \"mvm_rat1\": [], \"mvm_rat2\": []}\n",
    "\n",
    "    # loop over the frames of the video\n",
    "    n = 0\n",
    "    while True:\n",
    "        ret, frame = vs.read()  # ret says whether the frame exists\n",
    "\n",
    "        if frame is None:\n",
    "            break  # end of video if no more frames\n",
    "\n",
    "        # get timestamp of each frame...\n",
    "        frame_nb = n\n",
    "        millisec = str(vs.get(cv2.CAP_PROP_POS_MSEC))  # in millisecond\n",
    "        ts_dict = timestamping(ts_dict=ts_dict,\n",
    "                               frame_nb=frame_nb,\n",
    "                               millisec=millisec)\n",
    "\n",
    "        n += 1\n",
    "        # resize the frame, convert it to grayscale, and blur it\n",
    "        frame = resizing(frame=frame, scale_percent=scale_percent)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "        # get gray's shape for splitting............................................\n",
    "        height, width = gray.shape\n",
    "\n",
    "        # divide the frame and calculate background and change for each part\n",
    "        for i in range(n_cols):\n",
    "            tmp_img = gray[0:height, int(i * width / 2): int((i + 1) * width / 2)]  # take all hight and half of width\n",
    "\n",
    "            # initialize average frame (=background)\n",
    "            if len(avgframe[i]) == 0:\n",
    "                avgframe[i] = tmp_img.copy().astype(\"float\")\n",
    "\n",
    "            # update average & calculate difference between current and running avg\n",
    "            cv2.accumulateWeighted(tmp_img, avgframe[i], 0.5)\n",
    "            frameDelta[i] = cv2.absdiff(tmp_img,\n",
    "                                        cv2.convertScaleAbs(avgframe[i]))\n",
    "\n",
    "            # threshold the delta image, dilate the thresholded image to fill\n",
    "            # in holes, then find contours on thresholded image\n",
    "            thresh[i] = cv2.threshold(frameDelta[i], delta_thresh, 255,\n",
    "                                      cv2.THRESH_BINARY)[1]\n",
    "            thresh[i] = cv2.dilate(thresh[i], None, iterations=1)  # can spread the white pixels with itterations.. but we don't wanna\n",
    "\n",
    "        # append mvm count for each rat\n",
    "        for i in range(2):\n",
    "            ts_dict[f\"mvm_rat{i + 1}\"].append(np.sum(thresh[i]))\n",
    "            \n",
    "\n",
    "        # update FPS counter\n",
    "        fps.update()\n",
    "\n",
    "        # DISPLAY VIDEOS (IT'S 2x LONGER THIS WAY... 92:177 FPS)!!!\n",
    "        # cv2.imshow(\"webcam\", frame)\n",
    "        # cv2.imshow(\"Thresh_rat1\", thresh[0])\n",
    "        # cv2.imshow(\"Thresh_rat2\", thresh[1])\n",
    "        # cv2.imshow(\"Frame Delta_rat2\", frameDelta[1])\n",
    "\n",
    "        # cv2.waitKey(1)\n",
    "        keyboard = cv2.waitKey(1)\n",
    "        if keyboard == 'q' or keyboard == 27:\n",
    "            break\n",
    "\n",
    "        # testing, remove after...................................................................................\n",
    "        # if n > 25 * 60 * 1:\n",
    "        #    cv2.destroyAllWindows()\n",
    "        #    newpath, first_stamp = csv_name_creator(path, output_folder=output_4csv)\n",
    "        #    ts_df = pd.DataFrame(ts_dict)\n",
    "\n",
    "        #    ts_df['duration'] = [timedelta(milliseconds=float(i)) for i in ts_df['millisec']]\n",
    "        #    ts_df['duration'] = ts_df['duration'].values.astype('datetime64[ns]')\n",
    "        #    ts_df['duration'] = [i.strftime(\"%H:%M:%S.%f\")[:-3] for i in ts_df['duration']]\n",
    "\n",
    "        #    ts_df['timestamp'] = [pd.to_timedelta(str(i) + 'millisecond') +\n",
    "        #                          first_stamp for i in ts_df['millisec']]\n",
    "        #    ts_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "        #   order = [0, 1, 4, 2, 3]  # setting column's order\n",
    "        #  ts_df = ts_df[[ts_df.columns[i] for i in order]]\n",
    "\n",
    "        # ts_df.to_csv(csv_name_creator(path, output_folder=output_4csv)[0], sep='\\t')\n",
    "\n",
    "        # stop the timer and display FPS information\n",
    "        # fps.stop()\n",
    "        # print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "        # print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "        # return the df with timestamp+mvm count\n",
    "        # return ts_df..........................................................................................\n",
    "\n",
    "    # stop the timer and print Frame Per Sec info\n",
    "    fps.stop()\n",
    "    print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "    # CLEAN UP\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # get path for csv output & init of timestamp (extracted from the video filename)\n",
    "    newpath, first_stamp = csv_name_creator(path, output_folder=output_4csv)\n",
    "\n",
    "    # convert dict do pandas data frame...\n",
    "    ts_df = pd.DataFrame(ts_dict)\n",
    "\n",
    "    # create column 'duration' (millisec converted to time)\n",
    "    ts_df['duration'] = [timedelta(milliseconds=float(i)) for i in ts_df['millisec']]\n",
    "    # to keep only the time of the timedelta (otherwise give you estimate with days as well)\n",
    "    ts_df['duration'] = ts_df['duration'].values.astype('datetime64[ns]')\n",
    "    ts_df['duration'] = [i.strftime(\"%H:%M:%S.%f\")[:-3] for i in ts_df['duration']]\n",
    "\n",
    "    # ...set exact datetime timestamp (adding the first stamp to milliseconds)...\n",
    "    ts_df['timestamp'] = [pd.to_timedelta(str(i) + 'millisecond') +\n",
    "                          first_stamp for i in ts_df['millisec']]\n",
    "    ts_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    order = [0, 1, 4, 2, 3]  # setting columns' order\n",
    "    ts_df = ts_df[[ts_df.columns[i] for i in order]]\n",
    "\n",
    "    # ...and save it to info directory\n",
    "    ts_df.to_csv(newpath, sep='\\t')\n",
    "    # return ts_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vidpenv",
   "language": "python",
   "name": "vidpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
