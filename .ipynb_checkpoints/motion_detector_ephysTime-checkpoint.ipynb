{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8eb24628-9f3e-4e74-abae-1bcb36953c48",
   "metadata": {},
   "source": [
    "# **SET FRAME WIDTH as per EPHYS TIMESTAMP**\n",
    "\n",
    "**Notes:** try to set frame width with \n",
    "set(cv2.CAP_PROP_FRAME_WIDTH)... smt like that\n",
    "\n",
    "https://docs.opencv.org/3.4/d8/dfe/classcv_1_1VideoCapture.html#a473055e77dd7faa4d26d686226b292c1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5ccb4ba-1caa-4afc-a40d-730772342494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'calculate_video_timepoint.py',\n",
       " 'motion_detector_ephysTime.ipynb',\n",
       " 'plot_mvm.py',\n",
       " 'vid_processing.ipynb',\n",
       " 'video_process_pck',\n",
       " 'conv_dat2eeg.sh',\n",
       " 'readDat_SYNC.ipynb',\n",
       " 'file_cleaner.ipynb',\n",
       " 'conv_dat2eeg.ipynb',\n",
       " 'vid_processing-Copy1.ipynb',\n",
       " 'CSV_data',\n",
       " 'imro.ipynb']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "#os.chdir(\"../../\")\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6c8a4d7-03d3-4d1c-8d7a-b8e3151d07ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from video_process_pck.motion_detector import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "0eb2bac7-f897-46e2-af00-4e9453bb121a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#try: cap_prop_pos_msec... https://www.quora.com/How-do-I-decrease-the-frames-per-second-in-OpenCV-python\n",
    "\n",
    "def motion_detector(path, scale_percent=40, area=20, delta_thresh=5,\n",
    "                    output_4csv=\"/home/domi/Documents/video_processing/CSV_data\",\n",
    "                   ephys_time_path=\"/media/data-119/rat596_20210701_184333/rat596_20210701_184333tmstp.txt\"):\n",
    "    \"\"\"\n",
    "    path: path to the video\n",
    "    area: minimum area size.... TO INCLUDE!!!\n",
    "    ephys_time: path to ephys timestamp.. it will load it and calculate the differences (np.diff()) \n",
    "        -> iterable input for frame width (CAP_PROP_FRAME_WIDTH)\n",
    "    \"\"\"\n",
    "    # 1) EPHYS\n",
    "    #read file\n",
    "    e = open(ephys_time_path,\"r\")\n",
    "    ephys_time = [[int(x) for x in line.split()] for line in e]\n",
    "    e.close()\n",
    "    ephys_time = np.concatenate(ephys_time)\n",
    "    \n",
    "    #convert eph to MILLIseconds (-> then diff it -> NO NEED TO DO THIS IF  setting POS_MSEC)\n",
    "    ephys_time = ephys_time/2.5           # CORRECTION (#divide by sampling freq -> in secs now)\n",
    "                                         # don't leave it in sec.. should be in millisec (/2500 *1000)? \n",
    "    diff_ephys_time = np.diff(ephys_time)   #exact TIME differences between frames... seems like i can't use this\n",
    "    ephys_time_0 = [i - ephys_time[0] for i in ephys_time]\n",
    "    \n",
    "    \n",
    "    # 2) OUTPUT\n",
    "    #if specified output folder doesn't exist, create it\n",
    "#    if not os.path.exists(output_4csv):\n",
    "#        os.mkdir(output_4csv)\n",
    "\n",
    "    # 3) VID_PROC\n",
    "    # read from a video file \n",
    "    vs = cv2.VideoCapture(path)\n",
    "    \n",
    "    #initiate FramePerSec (FPS) count\n",
    "    fps = FPS().start()\n",
    "\n",
    "    # initialize average frame, frame delta and thresholded frame\n",
    "    avgframe = [[], []]\n",
    "    frameDelta = [[], []]\n",
    "    thresh = [[], []]\n",
    "\n",
    "    # initiate dictionary\n",
    "    ts_dict = {\"frame_nb\": [], \"millisec\": [], \"mvm_rat1\": [], \"mvm_rat2\": []}\n",
    "\n",
    "    # initiate dimensions for splitting\n",
    "    # n_rows=1\n",
    "    n_cols = 2  # 2 rats = 2 parts split with a vertical line\n",
    "    # division in the middle\n",
    "\n",
    "    # loop over the frames of the video\n",
    "    n = 0\n",
    "    \n",
    "    #DELETE AFTER___________________________________________________________________________________________\n",
    "    milliseconds = []\n",
    "    print(ephys_time[0])\n",
    "    #________________________________________________________________________________________________________\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        #SET FRAME WIDTH\n",
    "        try:\n",
    "            vs.set(cv2.CAP_PROP_POS_MSEC, ephys_time_0[n])\n",
    "        except IndexError:\n",
    "            print(\"More frames than ephys\")\n",
    "            pass\n",
    "        \n",
    "        ret, frame = vs.read()  # ret says whether the frame exists\n",
    "\n",
    "        if frame is None:\n",
    "            break  # end of video if no more frames\n",
    "\n",
    "        # get timestamp of each frame...\n",
    "        frame_nb = n\n",
    "        millisec = str(vs.get(cv2.CAP_PROP_POS_MSEC))  # in millisecond\n",
    "        \n",
    "        #DELETE AFTER___________________________________________________________________________________________\n",
    "        milliseconds.append(vs.get(cv2.CAP_PROP_POS_MSEC))\n",
    "        #_________________________________________________________________________________________________________\n",
    "        \n",
    "        ts_dict = timestamping(ts_dict=ts_dict,\n",
    "                               frame_nb=frame_nb,\n",
    "                               millisec=millisec)\n",
    "\n",
    "        n += 1\n",
    "        # resize the frame, convert it to grayscale, and blur it\n",
    "        frame = resizing(frame=frame, scale_percent=scale_percent)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (21, 21), 0)\n",
    "\n",
    "        # get gray's shape for splitting............................................\n",
    "        height, width = gray.shape\n",
    "\n",
    "        # divide the frame and calculate background and change for each part\n",
    "        for i in range(n_cols):\n",
    "            tmp_img = gray[0:height, int(i * width / 2): int((i + 1) * width / 2)]  # take all hight and half of width\n",
    "\n",
    "            # initialize average frame (=background)\n",
    "            if len(avgframe[i]) == 0:\n",
    "                avgframe[i] = tmp_img.copy().astype(\"float\")\n",
    "\n",
    "            # update average & calculate difference between current and running avg\n",
    "            cv2.accumulateWeighted(tmp_img, avgframe[i], 0.5)\n",
    "            frameDelta[i] = cv2.absdiff(tmp_img,\n",
    "                                        cv2.convertScaleAbs(avgframe[i]))\n",
    "\n",
    "            # threshold the delta image, dilate the thresholded image to fill\n",
    "            # in holes, then find contours on thresholded image\n",
    "            thresh[i] = cv2.threshold(frameDelta[i], delta_thresh, 255,\n",
    "                                      cv2.THRESH_BINARY)[1]\n",
    "            thresh[i] = cv2.dilate(thresh[i], None, iterations=1)  # spread the white pixels\n",
    "\n",
    "        # append mvm count for each rat\n",
    "        for i in range(2):\n",
    "            ts_dict[f\"mvm_rat{i + 1}\"].append(np.sum(thresh[i]))\n",
    "\n",
    "        # update FPS counter\n",
    "        fps.update()\n",
    "\n",
    "        # DISPLAY VIDEOS (IT'S 2x LONGER THIS WAY... 92:177 FPS)!!!\n",
    "        # cv2.imshow(\"webcam\", frame)\n",
    "        # cv2.imshow(\"Thresh_rat1\", thresh[0])\n",
    "        # cv2.imshow(\"Thresh_rat2\", thresh[1])\n",
    "        # cv2.imshow(\"Frame Delta_rat2\", frameDelta[1])\n",
    "\n",
    "        # cv2.waitKey(1)\n",
    "        keyboard = cv2.waitKey(1)\n",
    "        if keyboard == 'q' or keyboard == 27:\n",
    "            break\n",
    "\n",
    "        # testing, remove after...................................................................................\n",
    "#        if n > 25 * 60 * 1:\n",
    "            #print(milliseconds[n-1])\n",
    "        \n",
    "    cv2.destroyAllWindows()\n",
    "#           newpath, first_stamp = csv_name_creator(path, output_folder=output_4csv)\n",
    "    ts_df = pd.DataFrame(ts_dict)\n",
    "\n",
    "    ts_df['duration'] = [timedelta(milliseconds=float(i)) for i in ts_df['millisec']]\n",
    "    ts_df['duration'] = ts_df['duration'].values.astype('datetime64[ns]')\n",
    "    ts_df['duration'] = [i.strftime(\"%H:%M:%S.%f\")[:-3] for i in ts_df['duration']]\n",
    "\n",
    "#           ts_df['timestamp'] = [pd.to_timedelta(str(i) + 'millisecond') +\n",
    "#                                 first_stamp for i in ts_df['millisec']]\n",
    "#           ts_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "#          order = [0, 1, 4, 2, 3]  # setting column's order\n",
    "#          ts_df = ts_df[[ts_df.columns[i] for i in order]]\n",
    "\n",
    "# ts_df.to_csv(csv_name_creator(path, output_folder=output_4csv)[0], sep='\\t')\n",
    "\n",
    "# stop the timer and display FPS information\n",
    "    fps.stop()\n",
    "    print(\"[INFO] elasped time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "# return the df with timestamp+mvm count\n",
    "#            return ts_df#..........................................................................................\n",
    "    return milliseconds\n",
    "\n",
    "\n",
    "\n",
    "    # stop the timer and print Frame Per Sec info\n",
    "    fps.stop()\n",
    "    print(\"[INFO] elapsed time: {:.2f}\".format(fps.elapsed()))\n",
    "    print(\"[INFO] approx. FPS: {:.2f}\".format(fps.fps()))\n",
    "\n",
    "    # CLEAN UP\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # get path for csv output & init of timestamp (extracted from the video filename)\n",
    "    newpath, first_stamp = csv_name_creator(path, output_folder=output_4csv)\n",
    "\n",
    "    # convert dict do pandas data frame...\n",
    "    ts_df = pd.DataFrame(ts_dict)\n",
    "\n",
    "    # create column 'duration' (millisec converted to time)\n",
    "    ts_df['duration'] = [timedelta(milliseconds=float(i)) for i in ts_df['millisec']]\n",
    "    # to keep only the time of the timedelta (otherwise give you estimate with days as well)\n",
    "    ts_df['duration'] = ts_df['duration'].values.astype('datetime64[ns]')\n",
    "    ts_df['duration'] = [i.strftime(\"%H:%M:%S.%f\")[:-3] for i in ts_df['duration']]\n",
    "\n",
    "    # ...set exact datetime timestamp (adding the first stamp to milliseconds)...\n",
    "    ts_df['timestamp'] = [pd.to_timedelta(str(i) + 'millisecond') +\n",
    "                          first_stamp for i in ts_df['millisec']]\n",
    "    ts_df.set_index('timestamp', inplace=True)\n",
    "\n",
    "    order = [0, 1, 4, 2, 3]  # setting columns' order\n",
    "    ts_df = ts_df[[ts_df.columns[i] for i in order]]\n",
    "\n",
    "    # ...and save it to info directory\n",
    "    ts_df.to_csv(newpath, sep='\\t')\n",
    "    # return ts_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "afa7e348-871a-4682-a179-069bd27c21ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4022.4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2929421/199334749.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_nn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmotion_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/media/data-119/rat596_20210701_184333/rat596_20210701_184333.mp4\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_2929421/2585011586.py\u001b[0m in \u001b[0;36mmotion_detector\u001b[0;34m(path, scale_percent, area, delta_thresh, output_4csv, ephys_time_path)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;31m# resize the frame, convert it to grayscale, and blur it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresizing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_percent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscale_percent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/video_proc/video_process_pck/motion_detector.py\u001b[0m in \u001b[0;36mresizing\u001b[0;34m(frame, scale_percent)\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale_percent\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0mresized\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_nn=motion_detector(\"/media/data-119/rat596_20210701_184333/rat596_20210701_184333.mp4\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5e38d4dc-7378-44bc-b7f7-730d38155e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nn_sec=[i/1000 for i in df_nn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "af3ea0f8-924e-4067-8136-3ac4051f1f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1336934"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a50d537b-28d6-4b57-9eb7-d258a8d4961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnn=np.diff(df_nn_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5eaf2cee-0f49-4d05-934a-195b63131f13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04, 0.04, 0.04, ..., 0.  , 0.  , 0.  ])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afcd653d-632d-4999-a567-62761ebbf231",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vidpenv",
   "language": "python",
   "name": "vidpenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
